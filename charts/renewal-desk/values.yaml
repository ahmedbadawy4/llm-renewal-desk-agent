image:
  repository: renewal-desk
  tag: local
  pullPolicy: IfNotPresent

app:
  replicas: 1
  service:
    type: NodePort
    port: 8000
    nodePort: 30080
  corsOrigins:
    - http://localhost:30081
    - http://127.0.0.1:30081
  llmProvider: mock
  ollamaBaseUrl: http://host.docker.internal:11434
  ollamaModel: llama3.1:8b

grafana:
  enabled: true
  service:
    type: NodePort
    port: 3000
    nodePort: 30030

prometheus:
  enabled: true
  service:
    port: 9090

postgres:
  enabled: true
  service:
    port: 5432

minio:
  enabled: true
  service:
    port: 9000
    consolePort: 9001

otel:
  enabled: true
  service:
    port: 4318

dataDir: /data

ui:
  enabled: true
  image:
    repository: nginx
    tag: 1.27-alpine
    pullPolicy: IfNotPresent
  service:
    type: NodePort
    port: 80
    nodePort: 30081
  apiBaseUrl: http://localhost:30080

ollama:
  enabled: false
  image:
    repository: ollama/ollama
    tag: latest
    pullPolicy: IfNotPresent
  servicePort: 11434
  prePullModels:
    - llama3.1:8b
  persistence:
    enabled: true
    size: 7Gi
    storageClass: ""
    existingClaim: ""
    mountPath: /root/.ollama
  resources:
    requests:
      cpu: "1"
      memory: 4Gi
    limits:
      cpu: "2"
      memory: 8Gi
  podAnnotations: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
